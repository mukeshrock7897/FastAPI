{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# ðŸ“˜ 7\\_External\\_APIs\n",
    "\n",
    "**Integrating FastAPI with external APIs like OpenAI or Hugging Face**\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… Goal\n",
    "\n",
    "Use FastAPI to **send requests to 3rd-party APIs** (e.g., OpenAI) and return the results to your client.\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… Step 1: Install Required Packages\n",
    "\n",
    "```bash\n",
    "pip install fastapi uvicorn openai requests\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… Step 2: Setup OpenAI API Access\n",
    "\n",
    "```python\n",
    "# config.py\n",
    "OPENAI_API_KEY = \"your-api-key-here\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… Step 3: FastAPI Setup\n",
    "\n",
    "```python\n",
    "# main.py\n",
    "from fastapi import FastAPI, HTTPException\n",
    "from pydantic import BaseModel\n",
    "import openai\n",
    "from config import OPENAI_API_KEY\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… Step 4: Create Input Model\n",
    "\n",
    "```python\n",
    "class PromptInput(BaseModel):\n",
    "    prompt: str\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… Step 5: Generate with OpenAI API\n",
    "\n",
    "```python\n",
    "@app.post(\"/generate/\")\n",
    "def generate_text(data: PromptInput):\n",
    "    try:\n",
    "        response = openai.Completion.create(\n",
    "            model=\"text-davinci-003\",  # or gpt-3.5-turbo if using chat\n",
    "            prompt=data.prompt,\n",
    "            max_tokens=100\n",
    "        )\n",
    "        return {\"response\": response.choices[0].text.strip()}\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… Step 6: Run Server and Test\n",
    "\n",
    "```bash\n",
    "uvicorn main:app --reload\n",
    "```\n",
    "\n",
    "Test the endpoint:\n",
    "\n",
    "* POST to `/generate/` with JSON:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"prompt\": \"Write a short poem about the ocean.\"\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… HuggingFace Integration (Example)\n",
    "\n",
    "```python\n",
    "import requests\n",
    "\n",
    "@app.post(\"/huggingface/\")\n",
    "def use_huggingface_model(data: PromptInput):\n",
    "    HF_API = \"https://api-inference.huggingface.co/models/gpt2\"\n",
    "    headers = {\"Authorization\": \"Bearer YOUR_HF_TOKEN\"}\n",
    "\n",
    "    payload = {\"inputs\": data.prompt}\n",
    "    response = requests.post(HF_API, headers=headers, json=payload)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        raise HTTPException(status_code=500, detail=\"HuggingFace API failed\")\n",
    "\n",
    "    result = response.json()\n",
    "    return {\"generated_text\": result[0]['generated_text']}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… Summary Table\n",
    "\n",
    "| API          | Tool Used  | Endpoint        |\n",
    "| ------------ | ---------- | --------------- |\n",
    "| OpenAI       | `openai`   | `/generate/`    |\n",
    "| Hugging Face | `requests` | `/huggingface/` |\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ§  Tips\n",
    "\n",
    "* Store API keys securely (e.g., `.env` or secrets manager)\n",
    "* Validate user inputs to prevent abuse\n",
    "* Use rate-limiting for public APIs\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
