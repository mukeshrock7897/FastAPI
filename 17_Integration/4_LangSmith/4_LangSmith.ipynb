{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# ðŸ“˜ Integration with LangSmith\n",
    "\n",
    "[LangSmith](https://smith.langchain.com) helps monitor, debug, and visualize LangChain apps.\n",
    "You can plug it into FastAPI endpoints to log and trace LLM runs.\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… Step 1: Install Requirements\n",
    "\n",
    "```bash\n",
    "pip install fastapi uvicorn langchain langsmith openai\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… Step 2: Setup Environment\n",
    "\n",
    "Set your LangSmith and OpenAI credentials:\n",
    "\n",
    "```bash\n",
    "export LANGCHAIN_API_KEY=ls__your_langsmith_key\n",
    "export LANGCHAIN_PROJECT=my-fastapi-app\n",
    "export OPENAI_API_KEY=sk-xxxxxxx\n",
    "```\n",
    "\n",
    "Or use a `.env` file and load it with `python-dotenv`:\n",
    "\n",
    "```bash\n",
    "pip install python-dotenv\n",
    "```\n",
    "\n",
    "```env\n",
    "# .env\n",
    "LANGCHAIN_API_KEY=ls__your_langsmith_key\n",
    "LANGCHAIN_PROJECT=my-fastapi-app\n",
    "OPENAI_API_KEY=sk-xxxxxxx\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… Step 3: Create LLM Chain with LangSmith Tracing\n",
    "\n",
    "```python\n",
    "# chains.py\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langsmith import traceable\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"Translate to French: {text}\")\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# Optional: Decorator to enable tracing\n",
    "@traceable\n",
    "def run_chain(input_text: str) -> str:\n",
    "    return chain.run({\"text\": input_text})\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… Step 4: Create FastAPI Server\n",
    "\n",
    "```python\n",
    "# main.py\n",
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "from chains import run_chain\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "class Input(BaseModel):\n",
    "    text: str\n",
    "\n",
    "@app.post(\"/translate/\")\n",
    "async def translate(input: Input):\n",
    "    result = run_chain(input.text)\n",
    "    return {\"translated\": result}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… Step 5: Run Server\n",
    "\n",
    "```bash\n",
    "uvicorn main:app --reload\n",
    "```\n",
    "\n",
    "Send a request:\n",
    "\n",
    "```bash\n",
    "curl -X POST http://127.0.0.1:8000/translate/ \\\n",
    "     -H \"Content-Type: application/json\" \\\n",
    "     -d '{\"text\": \"Good morning\"}'\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… Step 6: View Traces in LangSmith\n",
    "\n",
    "1. Go to [https://smith.langchain.com](https://smith.langchain.com)\n",
    "2. Select your project: `my-fastapi-app`\n",
    "3. Explore input/output, token usage, and debugging info\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… Summary Table\n",
    "\n",
    "| Component           | Description                      |\n",
    "| ------------------- | -------------------------------- |\n",
    "| `@traceable`        | Traces your chain in LangSmith   |\n",
    "| `LANGCHAIN_PROJECT` | Groups logs by project name      |\n",
    "| FastAPI Endpoint    | Sends user input to chain        |\n",
    "| LangSmith           | Visualizes input, output, traces |\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ§  Optional Tips\n",
    "\n",
    "* Attach `metadata` or `tags` to traces for filtering\n",
    "* Use `tracer_v2 = LangChainTracer()` if doing advanced custom tracing\n",
    "* Supports other LLMs (Anthropic, Mistral, etc.)\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
